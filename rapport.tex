\documentclass[12pt]{article}

\usepackage{amsfonts, amsmath, amssymb, amstext, latexsym}
\usepackage{graphicx, epsfig}
\usepackage[utf8]{inputenc}
\usepackage[french]{babel}
\usepackage{exscale}
\usepackage{amsbsy}
\usepackage{amsopn}
\usepackage{fancyhdr}

\usepackage{amsmath, amssymb, amsfonts, amsthm, fouriernc, mathtools}
% mathtools for: Aboxed (put box on last equation in align envirenment)
\usepackage{microtype} %improves the spacing between words and letters

\usepackage{graphicx}
\usepackage{epsfig}
\usepackage{epstopdf}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% COLOR DEFINITIONS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage[svgnames]{xcolor} % Enabling mixing colors and color's call by 'svgnames'
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\definecolor{MyColor1}{rgb}{0.2,0.4,0.6} %mix personal color
\newcommand{\textb}{\color{Black} \usefont{OT1}{lmss}{m}{n}}
\newcommand{\blue}{\color{MyColor1} \usefont{OT1}{lmss}{m}{n}}
\newcommand{\blueb}{\color{MyColor1} \usefont{OT1}{lmss}{b}{n}}
\newcommand{\red}{\color{LightCoral} \usefont{OT1}{lmss}{m}{n}}
\newcommand{\green}{\color{Turquoise} \usefont{OT1}{lmss}{m}{n}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\usepackage{fullpage}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{caption} 
\usepackage{amsthm}
\usepackage{float}
\usepackage{amssymb}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% FONTS AND COLORS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%    SECTIONS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{titlesec}
\usepackage{sectsty}
%%%%%%%%%%%%%%%%%%%%%%%%
%set section/subsections HEADINGS font and color
\sectionfont{\color{MyColor1}}  % sets colour of sections
\subsectionfont{\color{MyColor1}}  % sets colour of sections

%set section enumerator to arabic number (see footnotes markings alternatives)
\renewcommand\thesection{\arabic{section}.} %define sections numbering
\renewcommand\thesubsection{\thesection\arabic{subsection}} %subsec.num.

%define new section style
\newcommand{\mysection}{
\titleformat{\section} [runin] {\usefont{OT1}{lmss}{b}{n}\color{MyColor1}}
{\thesection} {3pt} {} }

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%		CAPTIONS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{caption}
\usepackage{subcaption}
%%%%%%%%%%%%%%%%%%%%%%%%
\captionsetup[figure]{labelfont={color=Turquoise}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%		!!!EQUATION (ARRAY) --> USING ALIGN INSTEAD
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%using amsmath package to redefine eq. numeration (1.1, 1.2, ...)
%%%%%%%%%%%%%%%%%%%%%%%%
\renewcommand{\theequation}{\thesection\arabic{equation}}

%set box background to grey in align environment
\usepackage{etoolbox}% http://ctan.org/pkg/etoolbox
\makeatletter
\patchcmd{\@Aboxed}{\boxed{#1#2}}{\colorbox{black!15}{$#1#2$}}{}{}%
\patchcmd{\@boxed}{\boxed{#1#2}}{\colorbox{black!15}{$#1#2$}}{}{}%
\makeatother
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% DESIGN CIRCUITS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage[siunitx, american, smartlabels, cute inductors, europeanvoltages]{circuitikz}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\makeatletter
\let\reftagform@=\tagform@
\def\tagform@#1{\maketag@@@{(\ignorespaces\textcolor{red}{#1}\unskip\@@italiccorr)}}
\renewcommand{\eqref}[1]{\textup{\reftagform@{\ref{#1}}}}
\makeatother
\usepackage{hyperref}
\hypersetup{colorlinks=true}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% PREPARE TITLE
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{\blue Principes et Méthodes Statistiques \\
\blueb TP 2017}
\author{Pierre Bouvier, Nolwenn Cadic, Maxime Gourgoulhon}
\date{\today}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\noi}{\noindent}
\newcommand{\dsp}{\displaystyle}

\textheight 25cm
\textwidth 16cm
\oddsidemargin 0cm
\evensidemargin 0cm
\topmargin 0cm
\hoffset -0mm
\voffset -20mm


\pagestyle{plain}


\begin{document}

\maketitle
\baselineskip7mm

% \noi ENSIMAG $1^{\footnotesize \mbox{ère}}$ année   \hfill Mars 2017


\vspace{1cm}


\begin{center}
{\Large \bf Principes et Méthodes Statistiques

\vspace{3mm}

TP 2017

\vspace{3mm}

}
\end{center}

\noi \rule[0.5ex]{\textwidth}{0.1mm}


\section*{Introduction au problème}

Les données considérées sont issues d'une démarche d'analyse de signaux oculométri-ques, c'est-à-dire de signaux de suivi du mouvement des yeux au cours du temps. Ces signaux ont été mesurés sur des participants lors de tâches consistant à lire des textes traitant de thèmes prédéfinis : football, chasse aux oiseaux, physique nucléaire, art contemporain, etc...
L'objectif est que le lecteur identifie le thème du texte le plus vite possible.

Lors de la lecture, deux types de mouvements d'yeux alternent : la fixation, qui correspond à la lecture proprement dite d'un mot ou deux voire moins, et où les yeux sont quasi-immobiles, et la saccade, qui est un déplacement très rapide portant les yeux vers un autre mot ou une autre partie d'un mot long.

On considère un premier groupe de $n=227$ personnes à qui on a fait lire $n$ textes pris au hasard dans une première série de textes. On mesure pour chaque personne le nombre $X$ de fixations nécessaires pour identifier le type du texte lu. Les données sont fournies dans le fichier {\it groupe1.txt}.
Le fichier {\it groupe2.txt} contient des données similaires pour un second groupe de $m=168$ personnes à qui on a fait lire $m$ textes pris au hasard dans une autre série de textes.

L'objectif du TP est d'analyser ces données et de comparer les 2 groupes. On propose de modéliser la loi de probabilité de $X$ par une loi géométrique ou une loi binomiale négative.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Analyse d'échantillons de loi binomiale négative}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Une variable aléatoire $X$ est de loi binomiale négative ${\cal BN}(r,p)$ de paramètres $r \in \mathbb{N}^*$ et $p \in [0, 1]$  si elle est à valeurs dans $ \{r, r+1, ...\}$ et que :
$$P(X=x) = \binom{x-1}{r-1}(1-p)^{x-r}p^r, \, \forall x \in \{r, r+1, ...\}$$

Son espérance est $E[X]={\dsp \frac{r}{p}}$ et sa variance est $Var[X]={\dsp \frac{r(1-p)}{p^2}}$.

En {\tt R}, {\tt rnbinom(n,r,p)} simule un échantillon de taille $n$ d'une variable aléatoire $Y$ telle que $Y+r$ est de loi ${\cal BN}(r,p)$.

La loi géométrique ${\cal G}(p)$ est la loi ${\cal BN}(1,p)$. En {\tt R}, {\tt rgeom(n,p)} simule un échantillon de taille $n$ d'une variable aléatoire $Y$ telle que $Y+1$ est de loi ${\cal G}(p)$.

On considère un échantillon $X_1, \ldots, X_n$ de variables aléatoires indépendantes et de même loi ${\cal BN}(r,p)$.

Dans un premier temps, on suppose que le paramètre $r$ est connu.

\vspace{3mm}

\begin{enumerate}

\renewcommand{\labelenumi}{\arabic{section}.\arabic{enumi}.}

\item Estimer $p$ par la méthode des moments, puis par la méthode de maximum de vraisemblance. Montrer que les deux estimateurs sont égaux. On notera $\hat{p}_n$ cet estimateur.

\textbf{Réponse :\\}
\underline{méthode des moments :} $E[X] = \dsp \frac{r}{p} \Rightarrow p = \frac{e}{E[X]} \Rightarrow \hat{p}_n = \frac{r}{\bar{X}_n} $ \\
\underline{méthode du maximum de vraisemblance :} \\
Soit  la fonction de vraisemblance $\mathcal{L}(p, x_{1}, ..., x_{n})$,\\$$\mathcal{L}(p, x_{1}, ... , x_{n}) = \prod_{i=1}^{n}P(X=x_{i}, p)  = \prod_{i=1}^n \binom{x_i-1}{r-1}(1-p)^{x_i-r}p^r$$ \\
On cherche à trouver le minimum de cette fonction par rapport à p. \\
\[\frac{\partial{ln(\mathcal{L}(p, x_{1}, ... , x_{n}))}}{\partial{p}} = -\sum_{i=1}^{n} \frac{x_{i}}{1-p} + \frac{rn}{p(1-p)}\]
\[\frac{\partial{ln(\mathcal{L}(p, x_{1}, ... , x_{n}))}}{\partial{p}} = 0 \Rightarrow \frac{rn}{p} = -\sum_{i=1}{n} x_{i} \Rightarrow \hat{p}_n = \frac{r}{\bar{X}_n}\]
\vspace{3mm}

\item Appliquer le théorème central-limite à $\bar{X}_n$. En déduire un intervalle de confiance bilatéral asymptotique de seuil $\alpha$ pour $p$.

$$ IC = \left[ \frac{r}{\bar{X}_n} - u_{\alpha} \sqrt{r\frac{\bar{X}_n - r}{n\bar{X}_n^3}} ,\,\, \frac{r}{\bar{X}_n} + u_{\alpha} \sqrt{r\frac{\bar{X}_n - r}{n\bar{X}_n^3}}  \right] $$

\vspace{3mm}

\item Dans le cas de la loi géométrique ($r=1$), construire le graphe de probabilités avec la méthode usuelle basée sur la fonction de répartition. En déduire une estimation graphique $p_{g_1}$ de $p$. Evaluer la qualité de cette méthode sur la base de jeux de données simulées.


\textbf{Réponse : \\}
Calcul de la fonction de répartition pour le graphe : $$ F(k) = P(X \leq k) = \sum_{i=1}^{k} q^{i-1}p = p\sum_{i=0}^{n-1} q^{i} = 1 - q^{k}$$
On a $$ 1 - F(k) = q^{k} \Rightarrow ln(1-F(k)) = k ln(q)$$
On pose $H(x) = ln(1-x)$ et $g(x) = x$ et on obtient comme graphe de probabilité pour la fonction de répartition le nuage de points $ (g(x_i^{*}), \; h(\frac{i}{n})) \quad \forall i \in \llbracket 1; n \rrbracket $

\vspace{3mm}

\item Dans le cas de la loi binomiale négative avec $r>1$, cette méthode ne fonctionne pas car la fonction de répartition n'a pas d'expression simple. On propose alors une méthode similaire basée sur un autre critère.

\begin{enumerate}

\vspace{3mm}

\item Quand $X$ est de loi ${\cal BN}(r,p)$, calculer ${\dsp \frac{P(X=x)}{P(X=x+1)}}$.

\textbf{Réponse :\\}
$$\frac{P(X=x)}{P(X=x+1)} = \frac{\binom{x-1}{r-1} (1-p)^{x-r} p^{r}}{\binom{x}{r-1} (1-p)^{x-r+1} p^{r}} = \frac{1}{1-p} \frac{x-r+1}{x}$$

\vspace{3mm}

\item Proposer une méthode permettant d'évaluer à partir d'un nuage de points si la loi Binomiale Négative est un modèle plausible. En déduire deux estimations graphiques de $p$, $p_{g_2}$ et $p_{g_3}$.

\textbf{Réponse :\\}
\underline{1ère proposition :} En traçant les points $\left({\dsp \frac{x-r+1}{x}; \ \frac{P(x=X)}{P(X=x+1}} \right)$ pour tous les x. On obtient la pente $\dsp \frac{1}{1-p}$ et on peut facilement trouver p \\
\underline{2nde proposition :} En remarquant que $\dsp \frac{P(X=x)x}{P(X=x+1) (x-r+1)} = \frac{1}{1-p} $, on trace les points $\left(x, \dsp \frac{P(X=x)x}{P(X=x+1) (x-r+1)} \right) $ et on cherche la moyenne qui devrait correspondre à $ \dsp \frac{1}{1-p} $ 
\vspace{3mm}

\item Evaluer la qualité de cette méthode sur la base de jeux de données simulées.

\end{enumerate}

\vspace{3mm}

\hspace{-5mm} Dans un deuxième temps, on considère que les 2 paramètres $p$ et $r$ sont inconnus.

\vspace{3mm}

\item Calculer les estimateurs de $p$ et $r$ par la méthode des moments, $\tilde{p}_n$ et $\tilde{r}_n$.

\textbf{Réponse:\\}
On a, $ \dsp \frac{Var[X]}{E[X]} = \frac{1-p}{n} = \frac{1}{p} - 1 \Rightarrow \tilde{p}_n = \frac{\bar{X}_n}{S_n+\bar{X}_n} $ \\
Puisque $ r= p E[X]$, on obtient $\dsp \tilde{r}_n = \frac{ \bar{X}_n^2}{S_n + \bar{X}_n} $
\vspace{3mm}

\item Proposer une méthode numérique permettant de calculer les estimateurs de maximum de vraisemblance $\hat{p}_n$ et $\hat{r}_n$.

\textbf{Réponse :\\}
On estime p comme tout à l'heure (question 1.4 (b)
\end{enumerate}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Analyse des deux jeux de données}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{enumerate}

\renewcommand{\labelenumi}{\arabic{section}.\arabic{enumi}.}

\item Effectuer une analyse de statistique descriptive des 2 jeux de données, incluant des représentations graphiques et des calculs d'indicateurs statistiques. Commenter les résultats.

\textbf{Réponse : \\}

Calculs d'indicateurs statistiques grâce à R : \\

\begin{tabular}{|c|c|c |c |c |c |c|}

	\hline
	groupe &minimum & $1^{er}$ quartile & médiane & moyenne & $3^{eme}$ quartile & maximum \tabularnewline
	\hline
	groupe1 & 1.000 & 1.000& 5.000& 6.498 & 9.500 & 31.000 \tabularnewline
	\hline
	groupe2 & 6.00 & 13.00 & 20.00 & 19.74 & 25.00 & 50.00 \tabularnewline
	\hline
\end{tabular}

\vspace{1cm}


\begin{center}
\includegraphics[width = 15cm]{graphics/q2_1-groupe1.png}
\captionof{figure}{Histogramme à classes de même largeur groupe 1}
\label{fig2}
\end{center}



\begin{center}
\includegraphics[width = 15cm]{graphics/q2_1-groupe2.png}
\captionof{figure}{Histogramme à classes de même largeur groupe 2}
\label{fig2}
\end{center}


\item Les lois géométrique et binomiale négative sont-elles des modèles plausibles pour ces deux jeux de données ? Pour chaque jeu de données, choisir un modèle pertinent, estimer ses paramètres de toutes les façons possibles et, quand c'est possible, donner un intervalle de confiance asymptotique de seuil $\alpha=5\%$ pour ces paramètres.

\textbf{Réponse :\\}
Pour le groupe 1, au vu des analyses statistiques, la loi géométrique semble être un modèle pertinent. \\
Pour le groupe 2, c'est la loi binomiale négative qui semble être un modèle pertinent. \\

\vspace{3mm}

\textbf{\textit{Estimation graphique}}\\

Cas du groupe 1 : Après construction du graphe de probabilité, on pratique une régression linéaire pour connaître le coefficient directeur de la droite. \\
\begin{center}
\includegraphics[width=15cm]{{{graphics/q1.3}.eps}}
\captionof{figure}{Graphe de probabilité pour la loi géométrique sur le groupe 1}
\label{fig1}
\end{center}


D'après la question 1.3, on obtient une droite dont le coefficient directeur a est $a = ln(1-p) \Rightarrow p_{g_{1}} = 1 - e^{a} $ ce qui donne numériquement $ p=0,1507846 $\\
D'après la question 2.2, $ IC = [0.1354829, 0.1723137]$, En maximisant le maximum de vraisemblance on trouve $r=1$

\begin{center}
\includegraphics[width=15cm]{graphics/q2_2-groupe2.png}
\captionof{figure}{Graphe de probabilité pour la loi binomiale négative pour le groupe 2}
\label{fig3}
\end{center}

D'après la question $1.4(b)$, en traçant les points $\left( x, \dsp \frac{xP(x =X)}{P(X=x+1)} \right)$ on obtient une droite de pente $a = \dsp {1}{1-p} \Rightarrow p = 1 - \frac{1}{a}$ \\
Numériquement on obtient $ p_{g_{2}} = 0.4089586 $\\
En maximisant le maximum de vraisemblance grâce à un programme en R on trouve $r=5$

\textbf{\textit{Estimation numérique}}\\
En appliquant la méthode des moments au groupe 1 (question 1.1), on trouve $\tilde{p_n} = 0.1538983$ \\


\vspace{5mm}
En appliquant la méthode des moments au groupe 2 ( question 1.5), on trouve $\tilde{p_n} = 0.2476021 $  et $\tilde{r_n} = 4.887194$ or $\tilde{r_n}$ doit être un entier donc $\tilde{r_n} = 5$
D'après la question 2.2, $ IC = [0.2458528,0.260781]$

\item Pour les deux jeux de données, estimer le nombre moyen de fixations nécessaires pour identifier le type du texte lu et estimer la probabilité que ce nombre soit supérieur à 10. Quelle conclusion générale tirer de cette analyse ? \\
\vspace{3mm}

\textbf{Réponse :\\}
A la question précédente, nous avons calculé les différents paramètres nous permettant de déterminer l'espérance de chacune des lois et donc de déterminer le nombre moyen de fixations nécessaires pour identifier le type du texte lu. \\

 Pour le groupe 1, $E[X] = \frac{1}{p_{g_{1}}} = 6.631977 $ \\
Pour le groupe 2, $E[X] = \frac{r_{g_{2}}}{p_{g_{2}}} = 12.22618 $ (méthode graphique), mais on a également $E[X] = \frac{\tilde{r_n}}{\tilde{\tilde{p_n}}} = 19.7381$(méthode numérique) $\Rightarrow$ L'une au moins des deux méthode n'est pas pertinente

Intéressons nous à la probabilité que le nombre de fixations nécessaires pour déterminer le type de texte soit supérieur à 10, pour cela on compte le nombre de valeurs supérieures à 10 dans chacun des échantillons. \\
Pour le groupe 1 : $P(x \geq 10) = 0.2511013 $ \\²
Pour le groupe 2: $P(x \geq 10) = 0.9285714$\\

Tout d'abord notons que l'échantillon pour le groupe 2 ne comporte que 168 valeurs, ce qui n'est pas assez pour faire de bonnes approximations graphiques ce qui explique la différence entre les valeurs obtenues par méthode graphique et méthode des moments. De plus certaines valeurs semblent abérrantes au vu du graphe de probabilités pour la loi binomiale négative. \\
On remarque également que la majorité du  groupe deux est beaucoup plus rapide pour identifier le type du texte puisque la probabilité pour qu'il l'identifie en moins de 10 essais est supérieure à 0.90 contre un petit 0.25 pour le premier groupe.\\
Mais le nombre de mots nécessaires pour identifier le type de texte varie beaucoup plus pour le groupe 2 puisque le nombre moyen de mots est 12 avec 90 pourcent du nombre de mots nécessaires inférieur à 10. Cela signifie que certaines personnes ont eu besoin de beaucoup de mots pour déterminer le type de texte.\\
A l'inverse au sein du groupe 1, le nombre de mots nécessaires est plus centré autour de la valeur de 10, il y a très peu de personnes ayant eu besoin de beaucoup de mots.
Les valeurs pour le groupe 2 sont donc plus étalées que celles pour le groupe 1.


\end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Vérifications expérimentales à base de simulations}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{enumerate}

\renewcommand{\labelenumi}{\arabic{section}.\arabic{enumi}.}

\item Choisir $p$, $n$, $m$ et $\alpha$. Simuler $m$ d'échantillons de taille $n$ de la loi ${\cal G}(p)$. Pour chacun d'entre eux, calculer l'intervalle de confiance asymptotique de seuil $\alpha$ pour $p$ obtenu dans la question 2.2. Comparer la proportion d'intervalle contenant la vraie valeur de $p$ à $1-\alpha$. Quel est l'impact du choix des valeurs de $p$, $n$, $m$ et $\alpha$ ?

\vspace{3mm}

Paramètre fixés pour cette simulation, $p=0.15$, $m=1000$, $\alpha = 0.05$\\

\textbf{\textit{Ajouter ici le graphe 1 de la question 3.1}}

On remarque que plus n est grand, plus la probabilité que  p appartienne à l'intervalle de confiance est proche de la valeur théorique, à savoir de $1-\alpha$, donc plus l'estimation est précise.

\vspace{5mm}
Paramètres fixés pour cette simulation, $n=1000$, $m=1000$, $\alpha =0.05$ \\
\textbf{\textit{Ajouter ici le graphe 2 de la question 3.1}}

Grâce à ce graphe on remarque que la probabilité de l'échantillon n'influe pas sur la probabilité de se tromper en affirmant que p appartient à l'intervalle de confiance. 

\vspace{5mm}


Paramètres fixés pour cette simulation, $n=1000$, $p=0.15$, $\alpha = 0.05$ \\
\textbf{\textit{Ajouter ici le graphe 3 de la question 3.1}}

\vspace{5mm}


Paramètres fixés pour cette simulation, $n=10000$, $p=0.15$, $p=0.15$ \\

\textbf{\textit{Ajouter ici le graphe 4 de la question 3.1}}

Grâce au graphique, on voit que la probabilité que p appartienne à l'intervalle de confiance vaut $1-\alpha$. En augmentant alpha, on diminue le nombre de p dans l'intervalle de confiance.

\item Vérification de la loi faible des grands nombres. Simuler $m$ échantillons de taille $n$ de la loi ${\cal G}(p)$. Calculer le nombre de fois où l'écart en valeur absolue entre la moyenne empirique et l'espérance de la loi simulée est supérieure à un $\epsilon$ à choisir. Faire varier $n$ et conclure.

\vspace{3mm}

\item Vérification du théorème central-limite. Simuler $m$ échantillons de taille $n$ de la loi ${\cal G}(p)$. Sur l'échantillon des $m$ moyennes empiriques, tracer un histogramme et un graphe de probabilités pour la loi normale. Faire varier $n$ en partant de $n=5$ et conclure.

\vspace{3mm}

\item Choisir $r$, $p$, $n$ et $m$. Simuler $m$ échantillons de taille $n$ de la loi ${\cal BN}(r,p)$. Pour chaque échantillon, calculer les estimateurs des moments de $r$ et $p$, $\tilde{r}_n$ et $\tilde{p}_n$. Utilisez ces simulations pour évaluer le biais et l'erreur quadratique moyenne de ces estimateurs. Faire varier $n$ et commenter les résultats.

\vspace{5mm}
Nous avons évalué le biais et l'erreur quadratique de $\tilde{p_n}$ et $\tilde{r_n}$ avec les paramètres suivants : $p = 0.2$, $m=1000$, $r=5$

\textbf{\textit{Graphes à inserer ici et à commenter (Je ne sais pas à quoi il ressemblent, normalement ils tendent vers 0, si c'est effectivement le cas dire que quand n augmente, le biais et l'erreur quadratique diminuent}}

\end{enumerate}

\end{document}
